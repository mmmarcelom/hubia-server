#!/usr/bin/env python3
"""
HubIA Workflow Server
Servidor para processamento de tarefas distribu√≠das usando Ollama e modelos locais
"""

import asyncio
import os
import sys
from pathlib import Path
from dotenv import load_dotenv
sys.path.append(str(Path(__file__).parent))
from config import Config
from client import WorkflowClient
from processors.audio_processor import AudioProcessor

load_dotenv()

async def main():
    """Fun√ß√£o principal do servidor"""
    try:
        print("\n")
        print("üöÄ Iniciando HubIA Workflow Server...")
        
        # Load configuration
        config = Config()
        print(f"üåê {config.api_url}\n")
        
        # Verifica se temos SERVER_KEY antes de prosseguir
        if not config.server_key or config.server_key.strip() == "":
            print("‚ùå SERVER_KEY est√° vazia ou n√£o definida.")
            print("üìù √â necess√°rio fazer o registro do servidor primeiro.")
            print("üí° Execute o script de registro para obter uma SERVER_KEY v√°lida.")
            return
        
        # Verificar e instalar FFmpeg se necess√°rio
        audio_processor = AudioProcessor(config)
        audio_processor.ensure_ffmpeg_available()
        
        # Initialize workflow client
        client = WorkflowClient(config)
        
        await client.start()
        
    except KeyboardInterrupt:
        print("‚èπÔ∏è Servidor interrompido pelo usu√°rio")
    except Exception as e:
        print(f"‚ùå Erro fatal no servidor: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
